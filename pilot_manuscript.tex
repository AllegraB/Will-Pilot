\documentclass[,man]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Moral Foundations of U.S. Political News Organizations},
            pdfauthor={William E. Padfield~\& Erin M. Buchanan, Ph.D.},
            pdfkeywords={keywords},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{Moral Foundations of U.S. Political News Organizations}
    \author{William E. Padfield\textsuperscript{1}~\& Erin M. Buchanan,
Ph.D.\textsuperscript{1}}
    \date{}
  
\shorttitle{MORAL NEWS}
\affiliation{
\vspace{0.5cm}
\textsuperscript{1} Missouri State University}
\keywords{keywords\newline\indent Word count: X}
\usepackage{csquotes}
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

\usepackage{longtable}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{threeparttablex}

\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}


\DeclareDelayedFloatFlavor{ThreePartTable}{table}
\DeclareDelayedFloatFlavor{lltable}{table}
\DeclareDelayedFloatFlavor*{longtable}{table}
\makeatletter
\renewcommand{\efloat@iwrite}[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}
\makeatother
\usepackage{lineno}

\linenumbers

\authornote{Add complete departmental affiliations for each
author here. Each new line herein must be indented, like this line.

Enter author note here.

Correspondence concerning this article should be addressed to William E.
Padfield, 901 S. National Ave, Springfield, MO, 65897. E-mail:
\href{mailto:Padfield94@live.missouristate.edu}{\nolinkurl{Padfield94@live.missouristate.edu}}}

\abstract{
Enter abstract here. Each new line herein must be indented, like this
line.


}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

Something clever to start

\#\#Moral Foundations Theory

Jonathan Haidt and Jesse Graham formulated Moral Foundations Theory as a
method by which to capture the entirety of humans' moral domain. The
researchers argued older theories of moral psychology were focused
primarly on issues of justice, fairness, and caring - indvidually
focused foundations of morality that align with the beliefs of political
liberals ({\textbf{???}}). In other words, moral psychology ignored the
valid moral foundations of conservatives. Moral Foundations Theory (MFT)
holds that people's moral domain can be mapped by quantifying their
endorsement of five moral foundations: \emph{harm/care},
\emph{fairness/reciprocity}, \emph{ingroup/loyalty},
\emph{authority/respect}, and \emph{purity/sanctity} ({\textbf{???}}).

The researchers settled on these specific foundations after the
completion of a literature survey of research in anthropology and
evolutionary psychology ({\textbf{???}}). \emph{LET'S CHECK THIS
CITATION IN MENDELEY}!.The first two foundations (\emph{harm/care} and
\emph{fairness/reciprocity}) are termed the \enquote{individualizing
foundations,} as they are centered on the concerns of individuals rather
than groups. \emph{Harm/care} represents an endorsement of compassion
and kindness, while opposing cruelty and harm.
\emph{Fairness/reciprocity} represents concerns centered on guaranteeing
individual rights as well as justice and equality among all people. The
other three foundations (\emph{ingroup/loyalty},
\emph{authority/respct}, and \emph{purity/sanctity}) are the
\enquote{binding} foundations, owing to their focus on group-related
concerns, rather than those of individuals. \emph{Ingroup/loyalty}
represents endorsements of patriotism and heroism and discourages
nonconformity and dissent. \emph{Authority/respect} represents an
endorsement of social hierarchies and traditions while denigrating
disobedience. Finally, \emph{purity/sanctity} represents concerns
regarding chastity and piety, while discouraging vices and indulgences,
including lust, avarice, and gluttony ({\textbf{???}}). Liberals tend to
endorse the individualizing foundations more than conservatives.
Endorsements for the three binding foundations, however, are lower than
conservatives. Conservatives, on the other hand, tend to endorse all
five foundations equally, implying they base judments (at least
partially) on each foundation ({\textbf{???}}).

\#\#Moral Foundations Dictionary

In order to capture language's role in moral and political reasoning,
({\textbf{???}}) formulated the Moral Foundations Dictionary (MFD) in
order to capture moral reasoning and justification as used in speech and
text. The MFD is composed of 259 words, with around 50 words assigned to
each of the five foundations. The researchers created a preliminary list
of words that they believed would be associated with the five
foundations. Then, using the Linguistic Inquiry and Word Count (LIWC;
{\textbf{???}}) computer program, they analyzed transcripts of liberal
and conservative Christian sermons in order to obtain frequencies of the
occurrence of words from the researchers' initial list. The researchers
manually checked the results from LIWC in order to make sure the results
make sense given the contexts and rhetorical devices used in the
sermons. Similar to previous research on Moral Foundations Theory,
liberal ministers used \emph{harm}, \emph{fairness}, and \emph{ingroup}
words more often than conservative ministers. Conversely, conservative
ministers used \emph{authority} and \emph{purity} words more often than
liberal ministers. However, conservative ministers did not use
\emph{ingroup/loyalty} words more than liberals. Rather, liberal
ministers used words pertaining to \emph{ingroup/loyalty}, but in
contexts that promote rebellion and independence - causes
\emph{opposite} to positive endorsements of that foundation
({\textbf{???}}).

To this point, most text analysis utilizing the Moral Foundations
Dictionary operationalizes endorsement of any one of the foundations as
percent occurence of words from the foundation's respective word list.
As such, most analyses assume that zero percent occurence is indicative
of no endorsement, while any non-zero percent occurence indicates
endorsement of the foundation. This may not be sufficient in describing
the true nature of the writer or speaker's endorsement of one of the
sets of moral intuitions. A quick glance at the MFD words for
\emph{harm/care} reveals the presence of words that are more closely
associated with universally accepted conceptions of \emph{harm} over
\emph{care} and vice-versa ({\textbf{???}}). For example, the word
\enquote{cruel} has relatively negative connotations compared to
\enquote{benefit.} For the \emph{harm/care} foundation, it is
conceivable that use of the word \enquote{cruel} might indicate a
greater attentional focus of the idea of \emph{harm} rather than
\emph{care}.

For \emph{harm/care}, the definition of the foundation as well as its
name clearly distinguishes between two somewhat opposite sides of an
attentional continuum, with \emph{harm} on the negative end and
\emph{care} on the positive side. In other words, the entries in the MFD
for \emph{harm/care} have somewhat clear positive and negative valences.
The same pattern can be seen in the MFD entries for the other four
foundations. \emph{Purity/sanctity} features words that likely have a
negative valence to most observers, including \enquote{disease}" and
\enquote{trash,} along with more positive words, including
\enquote{right} and \enquote{sacred} ({\textbf{???}}). This, however,
brings up other questions regarding the definition and names of the
other four foundations apart from \emph{harm/care}:
\emph{fairness/reciprocity}, \emph{ingroup/loyalty},
\emph{authority/respect}, and \emph{purity/sanctity}. The latter four
foudnations have names that are harder to understand as a valence
continuum, as the concepts in the names are more similar, even to the
point of being virtually synonymous in the case of
\emph{fairness/reciprocity}.

When considering the issue of positive versus negative valence in MFD
words, the question of how texts are analyzed vis-a-vis the MFD remains.
How can raw percentage of MFD word occurence capture the valence and
focus of the writer or speaker? If 2\% of a politician's speech features
positive words (i.e. \enquote{benefit} and \enquote{defend}) from the
MFD \emph{harm/care} list, how can researchers be sure the level and
nature of the speaker's \enquote{endorsement} of the foundation equals
that of another politician whose speech contained negatively connoted
MFD words from the \emph{harm/care} list? They would have equal
endorsements as far as the numbers are concerned, but the words used and
focus given are on opposite sides of the \emph{harm/care} spectrum.

This issue is compounded by the fact the Moral Foundations Questionnaire
(MFQ) and its subscales assume endorsement lies on a continuum. One item
under the \emph{fairness/reciprocity} judgment subscale reads,
\enquote{Justice is the most important requirement for a society}
({\textbf{???}}). The survey respondent must select a number on a scale
from 1 to 6 indicating responses spanning \enquote{strongly disagree} at
1 to \enquote{strongly agree} at 6. While the scales in the MFQ do not
represent true valence as it pertains to individual words, it does allow
for a greater degree of specificity in terms of an individual's
endorsement of a particular moral foundation. When a respondent selects
a 4 for the aforementioned MFQ statement, they clearly are indicating
they \enquote{slightly agree} with the statement ({\textbf{???}}). This
specificity is not present in most analyses involving the MFD and
percent occurence, unless they also take into account the valence of the
words used in the text or speech of interest.

\#\#Valence

Borrowing from Osgood's work in the 1950s, ({\textbf{???}}) recognized
valence as one of three related dimensions comprising emotion when
developing their Affective Norms for English Words (ANEW). As mentioned
before, \enquote{valence,} the first dimension, denotes the pleasantness
of a given word. \enquote{Arousal,} the second dimension, describes the
stimulating nature of a word. Lastly, \enquote{dominance} or
\enquote{control} describes the extent to which a word makes one feel in
or out of control ({\textbf{???}}). The researchers developed ANEW by
presenting participants with a list of 100-150 words and asking for them
to rate the word on all three dimensions using the Self-Assessment
Mannikin (SAM), which allows ratings along either a nine-point scale
when using traditional paper instruments or a twenty-point scale when
using a computerized version.

Participants saw the stimulus word and responded on each scale. The
valence scale featured a smiling figure at one end (representing
pleasantness) and a frowning figure at the other end (for
unpleasantness). The arousal scale had a \enquote{wide-eyed} figure at
one end with a sleepy figure at the other, representing stimulating and
unstimulating respectively. Finally, the control scale featured a large
figure, indicating the highest degree of control, at one end and a small
figure, indicating a lack of control, at the other end ({\textbf{???}}).
The end result of this procedure yielded affective norms along the three
dimensions for 1,040 English words ({\textbf{???}}). ANEW represented an
important first step in establishing affective norms for large numbers
of English words. However, later researchers found the 1,040-word list
to be limiting for a language consisting of thousands of words.

({\textbf{???}}) exponentially lengthened the list of words with
affective norms to 13,915 English lemmas, the base forms of words
without inflection (i.e. \enquote{watch} rather than \enquote{watched}
and \enquote{watching}). The researchers recognized the importance of
affective norms in several areas of study, including emotion, language
processing, and memory ({\textbf{???}}). They argue the list of words
included in ANEW is sufficient for small-scale factorial research
designs, but the list is \enquote{prohibitively small} for larger-scale
\enquote{megastudies} that are common in psycholinguistic research today
({\textbf{???}}).

In order to source a large number of lemmas for affective ratings, the
researchers drew from several validated sources. These include the
30,000 lemmas with age-of-acquisition (average age at which a particular
word is learned) ratings gathered by Kuperman, Stadthagen-Gonzalez, and
Brysbaert as well as the content lemmas from the SUBTLEX-US corpus
consisiting of subtitles from various forms of visual media
({\textbf{???}}). This resulted in the final list of 13,915 lemmas.
Lists of 346-350 words were presented to participants recruited through
the Amazon Mechanical Turk subject pool. Particpants rated the words
along one of the three dimensions, unlike the ANEW project in which
participants rated each word along all three dimensions at once. The
researchers used a nine-point scale similar to the one used by
({\textbf{???}}) when collecting ratings for ANEW ({\textbf{???}}).

The researchers noted several points of interest upon observing ratings.
First, they found that valence and dominance ratings had a negative
skew, indicating more words elicited feelings of happiness and control
than their respective opposites. Also, when examining the relationship
between valence and arousal ratings, the researchers found a U-shaped
relationship. This indicates words with high degrees of positivity and
negativity elicited higher arousal ({\textbf{???}}). These observations
along with the now-greatly expanded list of affective norms has been
applied to several lines of inquiry in psycholinguistics.

({\textbf{???}}) utilized the new affective norms list in order to
investigate the validity of the Pollyanna hypothesis, or the prevalence
of a generally optimistic outlook in humans as reflected in langauge.
The researchers were able to conclude the existence of a greater number
of positive-valence English words in the list of 13,915 lemmas.
Additionally, after observing token frequency in a number of text
corpora, including SUBTLEX-US, COCA, BNC, TASA, and HAL, the researchers
found that words with postive valence were also used more frequently
({\textbf{???}}). While the researchers concede the possiblility of an
acquiensence bias in ratings as a possible explanation for the observed
positivity bias, this investigation represents one application of the
({\textbf{???}}) list in emotional studies.

One cognition-based study investigates the relationship between emotion
and response latencies in word recognition. ({\textbf{???}}) sought to
use the ({\textbf{???}}) norms to fill in the knowledge gaps regarding
variance in word recognition. The researchers drew several conclusions
regarding emotion and word recognition (specifically in naming and
lexical decision tasks). First, ({\textbf{???}}) found higher response
latencies in negative-valence words, lower response latencies in neutral
words, and even lower response latencies in words with positive valence.
The researchers also concluded that words causing higher arousal tend to
have higher response latencies than less-arousing words. They found
valence had a stronger effect on recognition than arousal (both effects
were independent, not interactive). They found an interaction between
emotion and word frequency such that valence and arousal are more
effective on lower frequency words than high frequency words. Finally,
({\textbf{???}}) found a greater effect for lexical decision tasks than
for naming tasks. This research serves as further evidence that the
({\textbf{???}}) list can be used for research inquiries both within and
without the field of psycholinguistics.

In the present studies, the researchers used the 2013 Warriner list in
order to denote the valence of the words appearing in the news articles
scraped from the internet. Valence was considered as another independent
variable and its relationship with the words comprising the Moral
Foundations Dictionary were of chief interest to the researchers. The
valence was used as a means to determine whether individiual words in
the MFD represented more positive aspects of their respective foundation
or if they denoted a more negative aspect of the foundation.
Incorporating word valence into a study involving the MFD is meant to
alleviate some of the issues regarding the aforementioned ambiguity
regarding the words in the Moral Foundations Dictionary.

\hypertarget{news-media-and-politics}{%
\subsection{News Media and Politics}\label{news-media-and-politics}}

Research into politics, language, and media has illuminated the complex
relationships between all three. Any politically-oriented discussion of
word occurence as an implication of moral or poltical position assumes
that langauge and ideology are intrisincally linked. Deborah Cameron
({\textbf{???}}) points out the expressive nature of ideological beliefs
and how that expression is conveyed through langauge, thus implying a
connection between ideology and language. She goes on to criticize the
notion that language is either the \enquote{pre-existing raw material}
used to shape ideologies or the \enquote{post-hoc vehicle} for their
propogation. Rather, the structure of language itself is shaped by
ideology and social processes even when it is used to explain or express
ideologies ({\textbf{???}}).

The use of language both to express and further an ideological goal has
been documented in the techniques employed by candidates for political
office in the U.S. For example, Druckman, Jacobs, and Ostermeier
(({\textbf{???}})) investigated issue and image priming on the part of
candidates as implied by the disproportionate attention candidates paid
to particular issues over others. In their research, the authors
consider \enquote{issues} as communication that attmepts to persuade
constituents to vote for the candidates based on their strengths in
matters of public policy. \enquote{Image} priming, on the other hand,
describes techniques deployed in order to sway votes based on favorable
aspects of the candidate's behavior and personality ({\textbf{???}}).
The researchers found numerous examples of issue and image priming
during the 1972 re-election campaign of Richard Nixon. They linked the
Nixon adminstration's awareness of the issues for which the president
had public support to the issues he should emphasize (and prime) during
the campaign. Likewise the researchers found evidence that Nixon's team
was aware of negative evaluations of his warmth and trustworthiness, and
thus took steps to prime his purportedly positive qualities, including
strength and competence ({\textbf{???}}).

({\textbf{???}}) also cited research from Iyengar and Kinder (1987)
suggesting the news media affected perceptions of President Jimmy
Carter's competence by emphasizing (read: priming) issues related to
energy, defense, and the economy. This implies news media may affect
perception of politicians based on where the media places emphasis.
Other research into news media suggests certain media outlets, at least
indirectly, may have an effect on the voting records of representatives
in Congress ({\textbf{???}}). Specifically, the researchers identified a
pattern of declining support for President Bill Clinton's policies
chiefly among Republicans in the House of Representatives after the Fox
News Channel began broadcasting on cable and satellite systems in their
respective districts. As Fox News was, at the time of its launch in
1996, the only outwardly ideological national news network, the
reserachers were able to track its spread across the country and observe
voting records of members of Congress both before and after Fox News'
arrival ({\textbf{???}}). The researchers concluded that members of
Congress, excluding those newly elected at the time of Fox News
Channel's emergence, attempted to anticipate resultant
conservative-leaning shifts among their constituents by bolstering their
conservative voting record before the next election ({\textbf{???}}).

Talk about political discourse, nature of news media in 2018/Trump
era/Kavanaugh

This project brings the two together in holy matrimony.

\hypertarget{experiment-1}{%
\section{Experiment 1}\label{experiment-1}}

\hypertarget{method}{%
\section{Method}\label{method}}

\hypertarget{sources}{%
\subsection{Sources}\label{sources}}

Political articles were scraped from the websites of four notable U.S.
news sources. The sources were \emph{The New York Times}, \emph{National
Public Radio (NPR)}, \emph{Fox News}, and \emph{Breitbart}. They were
selected for their widespread recognition and the fact they are easily
categorized (by the general public) according to perceived political
lean. In general, \emph{The New York Times} and \emph{NPR} are perceived
by many to have a liberal bias or lean. In contrast, Fox News and
Breitbart are believed to have a conservative bias or lean. Political
articles in particular were identified and subsequently scraped by
including the specific URL directing to each source's political content
in the \emph{R} script. For example, rather than scrape from
nytimes.com, which would return undesired results (non-political
features, reviews, etc.), we instead included
nytimes.com/section/politics so that more or less exclusively political
content was obtained. All code for this manuscript can be found at OSF
LINK, and the scripts are provided inline with this manuscript written
with the \emph{papaja} library ({\textbf{???}}).

Identification of the sources' political URLs presented a problem for
two of the sources owing to complications with how their particular
sites were structured. While in the multi-week process of scraping
articles, we noticed word counts for \emph{NPR} and \emph{Fox News} were
not growing at a similar pace as those from \emph{The New York Times}
and \emph{Breitbart}. Upon investigation, we found another, more robust
URL for political content from NPR: their politics content
\enquote{archive.} The page structure on NPR's website was such that
only a limited selection of articles is displayed to the user at a given
time. Scraping both the archive and the normal politics page ensured we
were obtaining most (if not all) new articles as they were published. We
later ran a process in order to exclude any duplicate articles.
\emph{Fox News} presented a similar issue. We discovered \emph{Fox News}
utilized six URLs in addition to the regular politics page. These URLs
led to pages containing content pertaining the U.S. Executive Branch,
Senate, House of Representatives, Judicial Branch, foreign policy, and
elections. Once again, duplicates were subsequently eliminated from any
analyses.

\hypertarget{materials}{%
\subsection{Materials}\label{materials}}

Using the \emph{rvest} library in the statistical package \emph{R}, we
pulled body text for individual articles from each of the aforementioned
sources (identified using CSS language) and compiled them into a dataset
({\textbf{???}}). Using this dataset, we identified word count and
average word count per source. This process was run once daily starting
on \emph{DATE} until \emph{DATE.} Starting on \emph{DATE,} the process
was run twice daily - once in the morning and again in the evening. Data
collection was terminated once 250,000 words per source was collected on
\emph{DATE.}

\hypertarget{data-analysis}{%
\subsection{Data analysis}\label{data-analysis}}

Once data collection ended, the text was scanned using the \emph{ngram}
package in \emph{R} ({\textbf{???}}). This package includes a word count
function, which was used to remove articles that came through as blank
text, as well as to eliminate text picked up from the Disqus commenting
system used by certain websites. At this point, duplicate articles were
discarded.

Using the ({\textbf{???}}) dictionary, the words making up each of the
five foundations in the MFD were assigned their respective valence
value. Once the MFD words' valences were added to the dataset, the
article text was processed using the \emph{tm} and \emph{ngram} packages
in \emph{R} in order to render the text in lowercase, remove
punctuation, and fix spacing issues ({\textbf{???}}). The individual
words were then reduced to their stems (i.e., \emph{abused} was stemmed
to \emph{abus}). The same procedure was applied to the MFD words and the
words in the ({\textbf{???}}) dataset.

DESCRIBE MTMM NEW STUFF HERE? Basically, words found through that
project were imported and added to each foundation, with reduncies
removed at the end.

The source article words were compiled into a dataset where they were
matched up with their counterparts in the MFD along with their valence
and a percentage of their occurrence. Therefore, for each article, the
percentage of the number of \emph{harm/care} words occurring in the
articles were calculated, and this process was repeated for each of the
foundations. This procedure created five percentages that were included
as the dependent variable for the following analyses.

\hypertarget{results}{%
\section{Results}\label{results}}

To analyze if news sources adhered to differences in word use based on
their target audience, we utilized a multilevel model (MLM) to analyze
the data. MLM is a regression technique that allows one to control for
the repeated measurement and nested structured of the data, which
creates correlated error ({\textbf{???}}). Using the \emph{nlme} library
in \emph{R} ({\textbf{???}}), each foundation's weighted percentage was
predicated by the political lean of the news soource, using the
individual news sources as a random intercept to control for the
structure of the data.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\hypertarget{experiment-2}{%
\section{Experiment 2}\label{experiment-2}}

\#\#Kavanaugh Supreme Court Hearing

In the wake of Justice Anthony Kennedy's retirement from the Supreme
Court of the United States, President Donald Trump nominated Brett
Kavanaugh as the new Associate Justice. Kavanaugh was previously on the
U.S. Court of Appeals for the District of Columbia. The Senate Judiciary
Committee began his confirmation hearing on September 4, 2018
({\textbf{???}}). Following allegations of sexual assault by high school
classmate Dr.~Christine Blasey Ford, the committee postponed its vote on
whether or not to open the confirmation to the entire Senate.

On September 27, the committee questioned Dr.~Ford before commencing a
second round of questioning for Judge Kavanaugh ({\textbf{???}}). During
the intervening weeks between hearings, two more women came forward with
two separate allegations of sexual assault on the part of Kavanaugh.
According to Nielsen reports, more than 20 million people watched the
September 27 proceedings on television ({\textbf{???}}). This figure
does not take into account viewers who watched online, nor does it
account for viewers outside the United States. On September 28, the
Senate Judiciary Committee voted to send the nomination to the Senate
floor. Senator Jeff Flake of Arizona, however, lobbied for a week-long
FBI investigation on Kavanaugh and the allegations facing him, which the
committee, and later the President, approved. The investigation
concluded with no significant findings. The Senate voted 50-48 to
approve Kavanaugh's appointment on October 6, 2018 ({\textbf{???}}).

The Kavanaugh nomination, confirmation hearing, and eventual
swearing-in, as well as the news media's coverage of all three events,
feature many moral dimensions that likely differ depending on one's
morals. On one side of the debate, Kavanaugh's Supreme Court tenure
presents a prime oppurtunity to bring morality back into interpretation
of the Constitution. Kavanaugh's confirmation creates a conservative
stronghold among the justices on the court. Commentators have noted this
might help advance a judicial agenda that backpedals certain rights
previously upheld by the Supreme Court, including abortion and gay
marriage - social issues challenged by their opponents at least
partially on moral grounds. On the other side of the debate, the assault
allegations have energized Kavanaugh's opponents to advocate for his
rejection from the court owing to misdeeds resulting from Kavanaugh's
own alleged lack of morals. Additionally, the moral duty of the Senate
as the upper chamber in the U.S. legislature has been scrutinized in
public discourse with respect to its handling of the assualt allegations
vis-a-vis Kavanaugh's confirmation.

\hypertarget{method-1}{%
\section{Method}\label{method-1}}

\hypertarget{sources-1}{%
\subsection{Sources}\label{sources-1}}

Experiment 2 largely followed the same method as Experiment 1. Political
articles specifically referring to Brett Kavanaugh and his Supreme Court
confirmation hearing were scraped

\hypertarget{materials-1}{%
\subsection{Materials}\label{materials-1}}

Expected material stuff - we are going to pick liberal and conservative
sources from that thing document linked stuff - list those here: Sources
used by LIBERALS (according to the document thing): The New Yorker Slate
The Daily Show (is it wise to use satirical news for this??) The
Guardian Al Jazeera America NPR New York Times Buzzfeed PBS BBC
Huffington Post Washington Post The Economist Politico MSNBC CNN NBC
News CBS News Google News Bloomberg ABC News USA TODAY

Sources used by CONSERVATIVES: Fox News Drudge Report Breitbart Rush
Limbaugh Show The Blaze Sean Hannity Glenn Beck (does he still report
\enquote{news}??)

\begin{itemize}
\tightlist
\item
  pick a specific date range we want to pull articles from
\item
  list that here:
\end{itemize}

START DATE: September 13, 2018

(September 27, 2018: Ford and Kavanaugh testimony before Senate
Judiciary Committee)

END DATE: October 11, 2018

here's when the stuff was happening and so picked two weeks before and
after

\hypertarget{data-analysis-1}{%
\subsection{Data analysis}\label{data-analysis-1}}

How you would run the data analysis

\hypertarget{experiment-2-results}{%
\section{Experiment 2 results}\label{experiment-2-results}}

\hypertarget{discussion-1}{%
\section{Discussion}\label{discussion-1}}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

How it turned out

Limitations of this one (no rationale behind choosing sources except
\enquote{people say NPR's liberal??})

What to do for future project (focus on one MF? Different sources? More
sources?)

Argue: why is still a good thing to study?? (probably something about
current state of discourse, information, truth, \enquote{alternative
facts,} subjective reality - philosophical stuff)

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}

\endgroup


\end{document}
