\documentclass[,man]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Moral Foundations of U.S. Political News Organizations},
            pdfauthor={William E. Padfield~\& Erin M. Buchanan, Ph.D.},
            pdfkeywords={politics, morality, psycholinguistics},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{Moral Foundations of U.S. Political News Organizations}
    \author{William E. Padfield\textsuperscript{1}~\& Erin M. Buchanan, Ph.D.\textsuperscript{1}}
    \date{}
  
\shorttitle{MORAL NEWS}
\affiliation{
\vspace{0.5cm}
\textsuperscript{1} Missouri State University}
\keywords{politics, morality, psycholinguistics}
\usepackage{csquotes}
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

\usepackage{longtable}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{threeparttablex}

\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}


\DeclareDelayedFloatFlavor{ThreePartTable}{table}
\DeclareDelayedFloatFlavor{lltable}{table}
\DeclareDelayedFloatFlavor*{longtable}{table}
\makeatletter
\renewcommand{\efloat@iwrite}[1]{\immediate\expandafter\protected@write\csname efloat@post#1\endcsname{}}
\makeatother
\usepackage{lineno}

\linenumbers

\authornote{Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

Enter author note here.

Correspondence concerning this article should be addressed to William E. Padfield, 901 S. National Ave, Springfield, MO, 65897. E-mail: \href{mailto:Padfield94@live.missouristate.edu}{\nolinkurl{Padfield94@live.missouristate.edu}}}

\abstract{
Enter abstract here. Each new line herein must be indented, like this line.


}

\begin{document}
\maketitle

In the United States, today's media landscape affords consumers a multitude of options for obtaining political news. Since the advent of cable news networks and the World Wide Web in the last decades of the twentieth century, consumers have gained access to an ever-expanding menagerie of news sources, many of which can be called up via a simple click, touch, or swipe. Concurrent with this growth in available news sources, concerns regarding political bias in news reporting have entered public consciousness. For example, commentators argue that networks including Fox News Channel and MSNBC communicate political news from a conservative and liberal slant respectively. These purported biases have been a cause for concern given the potential for incomplete or inaccurate news reporting potentially resulting from these biases. Given the inherently moral nature of many political arguments and positions, bias in news reporting might manifest as differing moral appeals. Specifically, the use of differing moral language in political articles might be an indicator of political bias in news media.

Morality and ethics have been of interest to thinkers, academics, and philosophers since antiquity. Starting chiefly in the twentieth century, a scientific approach to humans' understanding of morality emerged under the domain of psychology. Theories attempting to explain the development and application of people's moral intuitions built the foundation for the subfield of moral psychology. As the field developed, however, considerable debate has taken place regarding operational definitions of \enquote{morality.} This remains an issue in the field in the twenty-first century as researchers attempt to infer moral and political leanings from text and speech.

\hypertarget{moral-foundations-theory}{%
\subsection{Moral Foundations Theory}\label{moral-foundations-theory}}

As a discipline, modern moral psychology started in the late 1960s with Lawrence Kohlberg (Haidt \& Graham, 2007). Kohlberg's research popularized his theory of the development of moral reasoning. This theory establishes the steps of moral reasoning through which humans proceed as they mature. Kohlberg borrowed from Jean Piaget's stages of cognitive development in which children progress from the sensorimotor through to the formal operations stage (Haidt \& Graham, 2007). Similarly, Kohlberg found people typically start with a \enquote{pre-conventional} understanding of morality during infancy and progress through several steps until they reach a \enquote{post-conventional} ethics (Haidt \& Graham, 2007). People who have reached the post-conventional stage are said to be able to weigh competing abstractions and reason their way to a conclusion that promotes justice. From Kohlberg's perspective, issues of justice and fairness comprise the foundation of morality (Haidt \& Graham, 2007). This view persisted until it encountered criticism in the early 1980s.

Kohlberg's conception of morality faced major scrutiny from psychologist Carol Gilligan. In 1982, Gilligan criticized Kohlberg's theory on the grounds that it focused solely on the moral concerns of men, and that it ignored those of women (Haidt \& Graham, 2007). She offered a historic argument contending women have traditionally filled roles related to caring and nurturing. Gilligan thus asserted morality was built upon an alternative moral foundation: caring (Haidt \& Graham, 2007). This debate between competing conceptions of morality did not resolve until Gilligan and Kohlberg conceded the existence of two moral foundations: justice and caring (Haidt \& Graham, 2007). While this new direction in moral psychology appeared to represent a more inclusive outlook on the construct, these novel ideas would soon be challenged on the grounds of its apparent western-centric outlook.

In their brief overview of the history of moral psychology, Graham, Haidt, and Nosek (2009) explained Shweder, Much, Mahapatra, and Park's objections to moral psychology as it stood in the late 1980s. Their criticism centered on the fact moral psychology concerned itself with issues regarding justice and individuals' rights. Such a system, they argued, did not account for moral concerns outside of the western world (Graham et al., 2009). Individually focused concerns can be grouped under an overarching \enquote{ethic of autonomy,} which was thought to be one of three ethics upon which humans base moral decisions. The other two ethics were the \enquote{ethic of community} (comprising one's duty to their family, tribe, etc.) and the \enquote{ethic of divinity}" - representing one's duty not to defile their God-given body and soul (Graham et al., 2009). In the 2000s, Haidt and Graham (2007) took this line of reasoning further in their assertion that moral psychology favored certain political ideologies over others.

Jonathan Haidt and Jesse Graham formulated Moral Foundations Theory as a method by which to capture the entirety of humans' moral domain (Haidt \& Graham, 2007). The researchers argued older theories of moral psychology were focused primarily on issues of justice, fairness, and caring - individually focused foundations of morality that align with the beliefs of political liberals (Haidt \& Graham, 2007). In other words, moral psychology ignored the valid moral foundations of conservatives. Moral Foundations Theory (MFT) holds that people's moral domain can be mapped by quantifying their endorsement of five moral foundations: \emph{harm/care}, \emph{fairness/reciprocity}, \emph{ingroup/loyalty}, \emph{authority/respect}, and \emph{purity/sanctity} (Haidt \& Graham, 2007).

The researchers settled on these specific foundations after the completion of a literature survey of research in anthropology and evolutionary psychology (Graham et al., 2011). The researchers attempted to locate virtues and morals corresponding to \enquote{evolutionary thinking.} For instance, the researchers cited Mauss' work on reciprocal gift-giving, which informed the establishment of the \emph{fairness/reciprocity} foundation. Additionally, evolutionary literature on disgust and its correlation to human behavior regarding food and sex informed the \emph{purity/sanctity} foundation (Graham et al., 2011). The researchers identified the five \enquote{top candidates} for the foundations of human cultures' morality (Graham et al., 2011).

The first two foundations (\emph{harm/care} and \emph{fairness/reciprocity}) are termed the \enquote{individualizing foundations,} as they are centered on the concerns of individuals rather than groups. \emph{Harm/care} represents an endorsement of compassion and kindness, while opposing cruelty and harm. \emph{Fairness/reciprocity} represents concerns centered on guaranteeing individual rights as well as justice and equality among all people. The other three foundations (\emph{ingroup/loyalty}, \emph{authority/respect}, and \emph{purity/sanctity}) are the \enquote{binding} foundations, owing to their focus on group-related concerns, rather than those of individuals. \emph{Ingroup/loyalty} represents endorsements of patriotism and heroism and discourages nonconformity and dissent. \emph{Authority/respect} represents an endorsement of social hierarchies and traditions while denigrating disobedience. Finally, \emph{purity/sanctity} represents concerns regarding chastity and piety, while discouraging vices and indulgences, including lust, avarice, and gluttony (Haidt \& Graham, 2007). Liberals tend to endorse the individualizing foundations more than conservatives. Conservatives, on the other hand, tend to endorse the binding foundations more than liberals. It should be noted, however, conservatives also tend to endorse all five foundations equally, implying they base moral judgments on all foundations (Graham et al., 2009).

\hypertarget{moral-foundations-dictionary}{%
\subsection{Moral Foundations Dictionary}\label{moral-foundations-dictionary}}

In order to capture language's role in moral and political reasoning, Graham et al. (2009) formulated the Moral Foundations Dictionary (MFD) in order to capture moral reasoning and justification as used in speech and text. The MFD is composed of 259 words, with around 50 words assigned to each of the five foundations. The researchers created a preliminary list of words that they believed would be associated with the five foundations. Then, using the Linguistic Inquiry and Word Count (LIWC; Pennebaker, Booth, \& Frances, 2007) computer program, they analyzed transcripts of liberal and conservative Christian sermons in order to obtain frequencies of the occurrence of words from the researchers' initial list. The researchers manually checked the results from LIWC in order to make sure the results make sense given the contexts and rhetorical devices used in the sermons. The researchers offered the following example from a Unitarian sermon as a demonstration of ambiguous statements requiring human verification: \enquote{Don't let some self-interested ecclesiastical or government authority tell you what to believe, but read the Bible with your own eyes and open your heart directly to Jesus} (Graham et al., 2009). This sentence added to the \emph{authority/respect} total in LIWC's analysis, but it appears to suggest that one should reject authority in this context. The researchers eliminated this sentence from the \emph{authority/respect} raw count on account of this discrepancy between the use of authority-related words and the speaker's clear intentions (Graham et al., 2009).

Similar to previous research on Moral Foundations Theory, liberal ministers used \emph{harm}, \emph{fairness}, and \emph{ingroup} words more often than conservative ministers. Conversely, conservative ministers used \emph{authority} and \emph{purity} words more often than liberal ministers. However, conservative ministers did not use \emph{ingroup/loyalty} words more than liberals. Rather, liberal ministers used words pertaining to \emph{ingroup/loyalty}, but in contexts that promote rebellion and independence - causes \emph{opposite} to positive endorsements of that foundation (Graham et al., 2009).

To this point, most text analysis utilizing the Moral Foundations Dictionary operationalizes endorsement of any one of the foundations as percent occurrence of words in a given text from the foundation's respective word list. As such, most analyses assume that zero percent occurrence is indicative of no endorsement, while any non-zero percent occurrence indicates endorsement of the foundation. This operational definition may not be sufficient in describing the true nature of the writer or speaker's endorsement of one of the sets of moral intuitions. A quick glance at the MFD words for \emph{harm/care} reveals the presence of words that are more closely associated with universally accepted conceptions of \emph{harm} over \emph{care} and vice-versa (Graham et al., 2009). For example, the word \enquote{cruel} has relatively negative connotations compared to \enquote{benefit.} For the \emph{harm/care} foundation, it is conceivable that use of the word \enquote{cruel} might indicate a greater attentional focus of the idea of \emph{harm} rather than \emph{care}.

For \emph{harm/care}, the definition of the foundation, as well as its name, clearly distinguishes between two somewhat opposite sides of an attentional continuum, with \emph{harm} on the negative end and \emph{care} on the positive side. In other words, the entries in the MFD for \emph{harm/care} have somewhat clear positive and negative valences. The same pattern can be seen in the MFD entries for the other four foundations. \emph{Purity/sanctity} features words that likely have a negative valence to most observers, including \enquote{disease}" and \enquote{trash,} along with more positive words, including \enquote{right} and \enquote{sacred} (Graham et al., 2009). These dichotomies, however, bring up other questions regarding the definition and names of the other four foundations apart from \emph{harm/care}: \emph{fairness/reciprocity}, \emph{ingroup/loyalty}, \emph{authority/respect}, and \emph{purity/sanctity}. The latter four foundations have names that are harder to understand as a valence continuum, as the concepts in the names are more similar, even to the point of being virtually synonymous in the case of \emph{fairness/reciprocity}.

When considering the issue of positive versus negative valence in MFD words, the question of how texts are analyzed vis-a-vis the MFD remains. How can raw percentage of MFD word occurrence capture the valence and focus of the writer or speaker? If 2\% of a politician's speech features positive words (i.e. \enquote{benefit} and \enquote{defend}) from the MFD \emph{harm/care} list, how can researchers be sure the level and nature of the speaker's \enquote{endorsement} of the foundation equals that of another politician whose speech contained negatively connoted MFD words from the \emph{harm/care} list? They would have equal endorsements as far as the numbers are concerned, but the words used and focus given are on opposite sides of the \emph{harm/care} spectrum.

This issue is compounded by the fact the Moral Foundations Questionnaire (MFQ) and its subscales assume endorsement lies on a continuum. The Moral Foundations Questionnaire (MFQ), which was developed subsequent to the MFD, measures individuals' endorsements of each of the foundations using a six-point scale (Graham et al., 2011). The questionnaire is made up of judgment items and relevance items. Judgment items are phrased such that the respondent signals their agreement or disagreement with straightforward statements. An example of such a statement reads: \enquote{It can never be right to kill another human being} (Graham et al., 2011). Relevance items gauge the respondent's opinion regarding the importance of foundation-related concerns. For example, the respondent is directed to rate how important the following situation is to their sense of morals: \enquote{whether or not someone did something disgusting.} This example measures the relevance of the \emph{purity/sanctity} foundations. Each foundation has a judgment and relevance subscale, totaling 10 subscales for the MFQ (Graham et al., 2011).

The aforementioned ambiguity of the Moral Foundations Dictionary as an instrument becomes clearer upon closer examination of the items in the Moral Foundations Questionnaire. One item under the \emph{fairness/reciprocity} judgment subscale reads, \enquote{Justice is the most important requirement for a society} (Graham et al., 2011). The survey respondent must select a number on a scale from 1 to 6 indicating responses spanning \enquote{strongly disagree} at 1 to \enquote{strongly agree} at 6. While the scales in the MFQ do not represent true valence as it pertains to individual words, it does allow for a greater degree of specificity in terms of an individual's endorsement of a particular moral foundation. When a respondent selects a 4 for the aforementioned MFQ statement, they clearly are indicating they \enquote{slightly agree} with the statement (Graham et al., 2011). This specificity is not present in most analyses involving the MFD and percent occurrence, unless they also take into account the valence of the words used in the text or speech of interest.

\hypertarget{valence}{%
\subsection{Valence}\label{valence}}

Borrowing from Osgood's work in the 1950s, Bradley and Lang (1999) recognized valence as one of three related dimensions comprising emotion when developing their Affective Norms for English Words (ANEW). As mentioned before, \enquote{valence,} the first dimension, denotes the pleasantness of a given word. \enquote{Arousal,} the second dimension, describes the stimulating nature of a word. Lastly, \enquote{dominance} or \enquote{control} describes the extent to which a word makes one feel in or out of control (Bradley \& Lang, 1999). The researchers developed ANEW by presenting participants with a list of 100-150 words and asking for them to rate the word on all three dimensions using the Self-Assessment Mannikin (SAM), which allows ratings along either a nine-point scale when using traditional paper instruments or a twenty-point scale when using a computerized version.

Participants saw the stimulus word and responded on each scale. The valence scale featured a smiling figure at one end (representing pleasantness) and a frowning figure at the other end (for unpleasantness). The arousal scale had a \enquote{wide-eyed} figure at one end with a sleepy figure at the other, representing stimulating and unstimulating respectively. Finally, the control scale featured a large figure, indicating the highest degree of control, at one end and a small figure, indicating a lack of control, at the other end (Bradley \& Lang, 1999). The end result of this procedure yielded affective norms along the three dimensions for 1,040 English words (Bradley \& Lang, 1999). ANEW represented an important first step in establishing affective norms for large numbers of English words. However, later researchers found the 1,040-word list to be limiting for a language consisting of thousands of words.

Warriner, Kuperman, and Brysbaert (2013) exponentially lengthened the list of words with affective norms to 13,915 English lemmas, the base forms of words without inflection (i.e. \enquote{watch} rather than \enquote{watched} and \enquote{watching}). The researchers recognized the importance of affective norms in several areas of study, including emotion, language processing, and memory (Warriner et al., 2013). They argue the list of words included in ANEW is sufficient for small-scale factorial research designs, but the list is \enquote{prohibitively small} for larger-scale \enquote{megastudies} that are common in psycholinguistic research today (Warriner et al., 2013).

In order to source a large number of lemmas for affective ratings, the researchers drew from several validated sources. These include the 30,000 lemmas with age-of-acquisition (average age at which a particular word is learned) ratings gathered by Kuperman, Stadthagen-Gonzalez, and Brysbaert (2012) as well as the content lemmas from the SUBTLEX-US corpus consisting of subtitles from various forms of visual media (Warriner et al., 2013). This data collection resulted in the final list of 13,915 lemmas. Lists of 346-350 words were presented to participants recruited through the Amazon Mechanical Turk subject pool. Participants rated the words along one of the three dimensions, unlike the ANEW project in which participants rated each word along all three dimensions at once. The researchers used a nine-point scale similar to the one used by Bradley and Lang (1999) when collecting ratings for ANEW (Warriner et al., 2013).

The researchers noted several points of interest upon observing ratings. First, they found that valence and dominance ratings had a negative skew, indicating more words elicited feelings of happiness and control than their respective opposites. Also, when examining the relationship between valence and arousal ratings, the researchers found a U-shaped relationship. This indicates words with high degrees of positivity and negativity elicited higher arousal (Warriner et al., 2013). These observations along with the now-greatly expanded list of affective norms has been applied to several lines of inquiry in psycholinguistics.

Warriner and Kuperman (2015) utilized the new affective norms list in order to investigate the validity of the Pollyanna hypothesis, or the prevalence of a generally optimistic outlook in humans as reflected in language. The researchers were able to conclude the existence of a greater number of positive-valence English words in the list of 13,915 lemmas. Additionally, after observing token frequency in a number of text corpora, including SUBTLEX-US, COCA, BNC, TASA, and HAL, the researchers found that words with postie valence were also used more frequently (Warriner \& Kuperman, 2015). While the researchers concede the possibility of an acquiescence bias in ratings as a possible explanation for the observed positivity bias, this investigation represents one application of the Warriner et al. (2013) list in emotional studies.

In addition to applications in emotion research, the Warriner norms (2013) have been utilized in cognitive research as well. One cognition-based study investigates the relationship between emotion and response latencies in word recognition. Kuperman, Estes, Brysbaert, and Warriner (2014) sought to use the Warriner et al. (2013) norms to fill in the knowledge gaps regarding variance in word recognition. The researchers drew several conclusions regarding emotion and word recognition (specifically in naming and lexical decision tasks). First, Kuperman et al. (2014) found slower decision-making and reading times in negative-valence words, faster times in neutral words, and even faster times in words with positive valence. The researchers also concluded that words causing higher arousal tend to have slower decision times than less-arousing words. They found valence had a stronger effect on recognition than arousal (both effects were independent, not interactive). They found an interaction between emotion and word frequency such that valence and arousal are more effective on lower frequency words than high frequency words. Finally, Kuperman et al. (2014) found a greater effect of valence and arousal on response latency for lexical decision tasks than for naming tasks (Kuperman et al., 2014). This research serves as further evidence that the Warriner and Kuperman (2015) list can be used for research inquiries both within and without the field of psycholinguistics.

In the present studies, the researchers used the Warriner et al. (2013) list in order to denote the valence of the words appearing in the news articles scraped from the internet. Valence was considered as another independent variable and its relationship with the words comprising the Moral Foundations Dictionary were of chief interest to the researchers. The valence was used as a means to determine whether individual words in the MFD represented more positive aspects of their respective foundation or if they denoted a more negative aspect of the foundation. Incorporating word valence into a study involving the MFD is meant to alleviate some of the issues regarding the aforementioned ambiguity regarding the words in the Moral Foundations Dictionary.

\hypertarget{news-media-and-politics}{%
\subsection{News Media and Politics}\label{news-media-and-politics}}

Research into politics, language, and media has illuminated the complex relationships between all three. Any politically-oriented discussion of word occurrence as an implication of moral or political position assumes that language and ideology are intrinsically linked. Deborah Cameron (2006) points out the expressive nature of ideological beliefs and how that expression is conveyed through language, thus implying a connection between ideology and language. She goes on to criticize the notion that language is either the \enquote{pre-existing raw material} used to shape ideologies or the \enquote{post-hoc vehicle} for their propagation. Rather, the structure of language itself is shaped by ideology and social processes even when it is used to explain or express ideologies (Cameron, 2006). Owing to the fact the Moral Foundations Dictionary was developed in order to assess the moral, which includes the ideological, orientation of discourse, its purported ability to assess parts of the structure of language (vocabulary) for ideological lean is of chief interest to the researchers in the present study.

The use of language both to express and further an ideological goal has been documented in the techniques employed by candidates for political office in the U.S. Druckman, Jacobs, and Ostermeier ((2004)) considered political \enquote{issues} as communication that attempts to persuade constituents to vote for the candidates based on their strengths in matters of public policy. According to the researchers, \enquote{image} priming describes techniques deployed in order to sway votes based on favorable aspects of the candidate's behavior and personality (Druckman et al., 2004).The researchers investigated political issue and image priming on the part of candidates as implied by the disproportionate attention candidates paid to particular issues over others. The researchers found numerous examples of issue and image priming during the 1972 re-election campaign of Richard Nixon. They linked the Nixon administration's awareness of the issues for which the president had public support to the issues he should emphasize (and prime) during the campaign. Likewise the researchers found evidence that Nixon's team was aware of negative evaluations of his warmth and trustworthiness, and thus took steps to prime his purportedly positive qualities, including strength and competence (Druckman et al., 2004).

Druckman et al. (2004) also cited research from Iyengar and Kinder (1987) suggesting the news media affected perceptions of President Jimmy Carter's competence by emphasizing (e.g.~priming) issues related to energy, defense, and the economy. This focus implies news media may affect perception of politicians based on where the media places emphasis. Other research into news media suggests certain media outlets, at least indirectly, may have an effect on the voting records of representatives in Congress (Clinton \& Enamorado, 2014). Specifically, the researchers identified a pattern of declining support for President Bill Clinton's policies chiefly among Republicans in the House of Representatives after the Fox News Channel began broadcasting on cable and satellite systems in their respective districts. As Fox News was, at the time of its launch in 1996, the only outwardly ideological national news network, the researchers were able to track its spread across the country and observe voting records of members of Congress both before and after Fox News' arrival (Clinton \& Enamorado, 2014). The researchers concluded that members of Congress, excluding those newly elected at the time of Fox News Channel's emergence, attempted to anticipate resultant conservative-leaning shifts among their constituents by bolstering their conservative voting record before the next election (Clinton \& Enamorado, 2014).

\hypertarget{experiment-1}{%
\section{Experiment 1}\label{experiment-1}}

\hypertarget{method}{%
\section{Method}\label{method}}

For Experiment 1, the researchers approached the methodology with the intention to answer a method question. That is, this portion of the current research was conducted in order to solidify the best method by which to analyze political news text under the Moral Foundations Theory framework. The researchers hypothesized the news sources genrally perceived as liberal leaning (\emph{NPR} and \emph{The New York Times}) would contain MFD words and valences indicating endorsements of the individualizing moral foundations (\emph{harm/care} and \emph{fairness/reciprocity}). Additionally, the researchers hypothesized the two sources generally perceived to be conservative leaning (\emph{Fox News} and \emph{Breitbart}) would feature MFD words and valences indicating equal endorsement of all five foundations.

\hypertarget{sources}{%
\subsection{Sources}\label{sources}}

Political articles were scraped from the websites of four notable U.S. news sources. The sources were \emph{The New York Times}, \emph{National Public Radio (NPR)}, \emph{Fox News}, and \emph{Breitbart}. They were selected for their widespread recognition and the fact they are easily categorized (by the general public) according to perceived political lean. In general, \emph{The New York Times} and \emph{NPR} are perceived by many to have a liberal bias or lean. In contrast, Fox News and Breitbart are believed to have a conservative bias or lean (Mitchell, Matsa, Gottfried, \& Kiley, 2014). Political articles in particular were identified and subsequently scraped by including the specific URL directing to each source's political content in the \emph{R} script. For example, rather than scrape from nytimes.com, which would return undesired results (non-political features, reviews, etc.), we instead included nytimes.com/section/politics so that more or less exclusively political content was obtained. All code for this manuscript can be found at OSF LINK, and the scripts are provided inline with this manuscript written with the \emph{papaja} library (Aust \& Barth, 2017).

Identification of the sources' political URLs presented a problem for two of the sources owing to complications with how their particular sites were structured. While in the multi-week process of scraping articles, we noticed word counts for \emph{NPR} and \emph{Fox News} were not growing at a similar pace as those from \emph{The New York Times} and \emph{Breitbart}. Upon investigation, we found another, more robust URL for political content from NPR: their politics content \enquote{archive.} The page structure on NPR's website was such that only a limited selection of articles is displayed to the user at a given time. Scraping both the archive and the normal politics page ensured we were obtaining most (if not all) new articles as they were published. We later ran a process in order to exclude any duplicate articles. \emph{Fox News} presented a similar issue. We discovered \emph{Fox News} utilized six URLs in addition to the regular politics page. These URLs led to pages containing content pertaining the U.S. Executive Branch, Senate, House of Representatives, Judicial Branch, foreign policy, and elections. Once again, duplicates were subsequently eliminated from any analyses.

\hypertarget{materials}{%
\subsection{Materials}\label{materials}}

Using the \emph{rvest} library in the statistical package \emph{R}, we pulled body text for individual articles from each of the aforementioned sources (identified using CSS language) and compiled them into a dataset ({\textbf{???}}). Using this dataset, we identified word count and average word count per source. This process was run once daily starting on \emph{DATE} until \emph{DATE.} Starting on \emph{DATE,} the process was run twice daily - once in the morning and again in the evening. Data collection was terminated once 250,000 words per source was collected on \emph{DATE.}

\hypertarget{data-analysis}{%
\subsection{Data analysis}\label{data-analysis}}

Once data collection ended, the text was scanned using the \emph{ngram} package in \emph{R} (Schmidt, Gonzalez-Cabrera, \& Tomasello, 2017). This package includes a word count function, which was used to remove articles that came through as blank text, as well as to eliminate text picked up from the Disqus commenting system used by certain websites. At this point, duplicate articles were discarded.

The article text was processed using the \emph{tm} and \emph{ngram} packages in \emph{R} in order to render the text in lowercase, remove punctuation, and fix spacing issues ({\textbf{???}}). The individual words were then reduced to their stems (i.e., \emph{abused} was stemmed to \emph{abus}). The same procedure was applied to the MFD words and the words in the Warriner et al. (2013) dataset. Using the Warriner et al. (2013) dictionary, the words making up each of the five foundations in the MFD were assigned their respective valence value.

DESCRIBE MTMM NEW STUFF HERE? Basically, words found through that project were imported and added to each foundation, with redundancies removed at the end.

The source article words were compiled into a dataset where they were matched up with their counterparts in the MFD along with their valence and a percentage of their occurrence. Therefore, for each article, the percentage of the number of \emph{harm/care} words occurring in the articles were calculated, and this process was repeated for each of the foundations. This procedure created five percentages that were included as the dependent variable for the following analyses. It should be noted the valence scores for the MFD words were \emph{z}-scored, so negative valence scores are possible.

\hypertarget{results}{%
\section{Results}\label{results}}

To analyze if news sources adhered to differences in word use based on their target audience, we utilized a multilevel model (MLM) to analyze the data. MLM is a regression technique that allows one to control for the repeated measurement and nested structured of the data, which creates correlated error (Gelman, 2006). Using the \emph{nlme} library in \emph{R} (Pinheiro, Bates, Debroy, Sarkar, \& Team, 2017), each foundation's weighted percentage was predicated by the political lean of the news source, using the individual news sources as a random intercept to control for the structure of the data.

The multilevel model did not indicate the presence of any significant or practical effect of political lean for any of the five moral foundations. The strongest effect size was observed for the \emph{authority/respect} foundation, but the effect was in the opposite direction from what was originally hypothesized - liberal sources tended to use more \emph{authority/respect} words than did conservative sources. Descriptive and test statistics, \emph{p}-values and effect sizes (Cohen's \emph{d}) can be found in Table 1.

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\caption{\label{tab:exp1-table}stuff at the top}
\begin{tabular}{lccccccc}
\toprule
Foundation & $M_C$ & $SD_C$ & $M_L$ & $SD_L$ & $t$ & $p$ & $d$\\
\midrule
Harm/Care & 0.50 & 2.21 & 0.49 & 2.21 & -0.21 & .850 & 0.01\\
Fairness/Reciprocity & 1.13 & 1.38 & 1.11 & 1.38 & -0.42 & .715 & 0.02\\
Ingroup/Loyalty & 1.28 & 1.63 & 1.34 & 1.63 & 0.30 & .789 & -0.04\\
Authority/Respect & 0.72 & 1.62 & 1.06 & 1.62 & 3.17 & .087 & -0.20\\
Purity/Sanctity & 1.11 & 1.48 & 1.27 & 1.48 & 2.37 & .141 & -0.09\\
\bottomrule
\addlinespace
\end{tabular}
\begin{tablenotes}[para]
\normalsize{\textit{Note.} something useful here}
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

The results obtained in Experiment 1 did not confirm the hypothesis. The researchers found little compelling evidence of an effect of partisan lean on MFD endorsement. The strongest effect found was for the \emph{authority/respect} foundation owing to the fact its Cohen's \emph{d} value was greater than the other four foundations. However, the effect was in the opposite direction of that which was hypothesized. Specifically, the results indicated that liberal leaning sources demonstrated higher endorsement of that foundation than conservatives. This is contrary not only to the research hypothesis for Experiment 1 but also to previous findings in Moral Foundations Theory research. It should be noted, however, the effect size was small and the relationship was not found to be statistically significant.

Upon speculation, the researchers identified one possible reason for why the results were unable to confirm the hypothesis. The selection of the broad and amorphous topic of \enquote{political news} may have led to the scraping of large numbers of articles with little to no moral-centric content. Rather, many articles may have been, for example, simple reporting on congressional procedures that would leave little room for the use of moral language let alone words from the Moral Foundations Dictionary. In short, the range of topics covered in Experiment 1 was likely too broad. The possibility exists that a tighter focus on one political issue or event, especially one that (on the surface) has a stronger relationship with morality might be more illuminating for research in moral language in news media.

Owing to the exploratory nature of Experiment 1, the researchers were afforded the opportunity to consider changes to the method to be utilized in Experiment 2. The researchers identified two primary changes in methodology that were subsequently employed in Experiment 2. First, the researchers elected to include more news sources for web scraping and analysis in addition to the four used in Experiment 1. Second, the researchers chose to focus their data collection efforts exclusively on one event in U.S. politics: the nomination and confirmation of Justice Brett Kavanaugh to the U.S. Supreme Court. In Experiment 2, the researchers sought to confirm the usefulness and validity of the method as well as test a similar hypothesis as Experiment 1.

\hypertarget{experiment-2}{%
\section{Experiment 2}\label{experiment-2}}

\hypertarget{kavanaugh-supreme-court-hearing}{%
\subsection{Kavanaugh Supreme Court Hearing}\label{kavanaugh-supreme-court-hearing}}

In the wake of Justice Anthony Kennedy's retirement from the Supreme Court of the United States, President Donald Trump nominated Brett Kavanaugh as the new Associate Justice. Kavanaugh was previously on the U.S. Court of Appeals for the District of Columbia. The Senate Judiciary Committee began his confirmation hearing on September 4, 2018 ({\textbf{???}}). Following allegations of sexual assault by high school classmate Dr.~Christine Blasey Ford, the committee postponed its vote on whether or not to open the confirmation to the entire Senate.

On September 27, the committee questioned Dr.~Ford before commencing a second round of questioning for Judge Kavanaugh ({\textbf{???}}). During the intervening weeks between hearings, two more women came forward with two separate allegations of sexual assault on the part of Kavanaugh. According to Nielsen reports, more than 20 million people watched the September 27 proceedings on television (O'Connell, 2018). This figure does not take into account viewers who watched online, nor does it account for viewers outside the United States. On September 28, the Senate Judiciary Committee voted to send the nomination to the Senate floor. Senator Jeff Flake of Arizona, however, lobbied for a week-long FBI investigation on Kavanaugh and the allegations facing him, which the committee, and later the President, approved. The investigation concluded with no significant findings. The Senate voted 50-48 to approve Kavanaugh's appointment on October 6, 2018 ({\textbf{???}}).

The Kavanaugh nomination, confirmation hearing, and eventual swearing-in, as well as the news media's coverage of all three events, feature many moral dimensions that likely differ depending on one's morals. On one side of the debate, Kavanaugh's Supreme Court tenure presents a prime opportunity to bring morality back into interpretation of the Constitution. Kavanaugh's confirmation creates a conservative stronghold among the justices on the court. Commentators have noted this might help advance a judicial agenda that backpedals certain rights previously upheld by the Supreme Court, including abortion and gay marriage - social issues challenged by their opponents at least partially on moral grounds. On the other side of the debate, the assault allegations have energized Kavanaugh's opponents to advocate for his rejection from the court owing to misdeeds resulting from Kavanaugh's own alleged lack of morals. Additionally, the moral duty of the Senate as the upper chamber in the U.S. legislature has been scrutinized in public discourse with respect to its handling of the assault allegations vis-a-vis Kavanaugh's confirmation.

In contrast to Experiment 1, the researchers approached Experiment 2 with the intention to confirm the method employed was valid for the analysis of the scraped text as well as for any inferences drawn from the analyses. For Experiment 2, the researchers hypothesized that news sources perceived as liberal will exhibit positive endorsements of the individualizing moral foundations (\emph{harm/care} and \emph{fairness/reciprocity}) in their articles reporting on the Kavanaugh confirmation hearing. News sources perceived as conservative are hypothesized to positively endorse all five foundations equally in their coverage of the Kavanaugh hearing. The researchers tested the hypothesis by analyzing the content scraped from news sources' web pages during the two weeks Kavanaugh's confirmation was prominent in the news. The content will be analyzed for valence and moral alignment under Moral Foundations Theory.

\hypertarget{method-1}{%
\section{Method}\label{method-1}}

\hypertarget{sources-1}{%
\subsection{Sources}\label{sources-1}}

Articles pertaining to the Brett Kavanaugh Supreme Court nomination and confirmation were scraped from the websites of 12 U.S. news sources. These sources were selected owing to their favorability among political partisans according to Mitchell et al. (2014). The sources favored by liberals were \emph{The New York Times}, \emph{National Public Radio (NPR)}, \emph{MSNBC}, \emph{Slate}, \emph{Huffington Post}, and \emph{Politico} (Mitchell et al., 2014). The sources favored by conservatives included \emph{Fox News}, \emph{Breitbart}, \emph{The Drudge Report}, \emph{The Rush Limbaugh Show}, \emph{The Blaze}, and \emph{Sean Hannity}. Political articles referencing Brett Kavanaugh's nomination process were identified and subsequently scraped by including the URL for each source's coverage of the nomination in the \emph{R} script. All code for this manuscript can be found at OSF LINK, and the scripts are provided inline with this manuscript written with the \emph{papaja} library (Aust \& Barth, 2017).

\hypertarget{materials-1}{%
\subsection{Materials}\label{materials-1}}

Using the \emph{rvest} library in the statistical package \emph{R}, we pulled body text for individual articles from each of the following 12 sources (identified using CSS language): \emph{The New York Times}, \emph{National Public Radio (NPR)}, \emph{MSNBC}, \emph{Slate}, \emph{Huffington Post}, \emph{Politico}, \emph{Fox News}, \emph{Breitbart}, \emph{The Drudge Report}, \emph{The Rush Limbaugh Show}, \emph{The Blaze}, and \emph{Sean Hannity}. We compiled the articles into a dataset ({\textbf{???}}). Using this dataset, we identified word count and average word count per source. This process was run for articles pertaining to Kavanaugh's nomination that were published between September 13, 2018 and October 11, 2018 inclusive. This date range was selected in reference to the widely-publicized and viewed nomination hearing on September 27, 2018. We set the start date at September 13 (two weeks before the hearing) and the end date at October 11 (two weeks after the hearing) so that we could capture a large amount of data (roughly one month) during which Kavanaugh's nomination was at its peak saturation in news coverage.

Expected material stuff
- we are going to pick liberal and conservative sources from that thing document linked stuff
- list those here:
Sources used by LIBERALS:
Slate
Huffington Post
NPR
New York Times
Politico

Sources used by CONSERVATIVES:
Fox News
Breitbart
Rush Limbaugh Show
The Blaze
Sean Hannity

DROPPED:
Glenn Beck (does he still report \enquote{news}??)
The Daily Show (is it wise to use satirical news for this??) - Answer = Nope
The Guardian (not American)
The New Yorker
Al Jazeera America
Buzzfeed
PBS
BBC
Washington Post
The Economist
CNN
NBC News
CBS News
Google News
Bloomberg
ABC News
USA TODAY
Drudge Report \emph{HEY! THIS IS MOSTLY AN AGGREGATOR!!! IS IT STILL OK? The answer is NOPE}
MSNBC \emph{CLOSEST TO POLITICAL CENTER; buh-bye!}

START DATE: September 13, 2018

(September 27, 2018: Ford and Kavanaugh testimony before Senate Judiciary Committee)

END DATE: October 11, 2018

here's when the stuff was happening and so picked two weeks before and after

\hypertarget{data-analysis-1}{%
\subsection{Data analysis}\label{data-analysis-1}}

As in Experiment 1, the text was scanned using the \emph{ngram} package in \emph{R} at the conclusion of data collection (Schmidt et al., 2017). Using the package's word count function, articles that came through as blank text were removed, as well as text scraped from the Disqus commenting system. Duplicate articles were subsequently discarded.

Using the \emph{tm} and \emph{ngram} packages in \emph{R}, the researchers processed the text in order to convert it to lowercase, fix spacing anomalies, and remove punctuation (Feinerer \& Hornik, 2017). Each individual word was reduced to its stem (i.e., \emph{diseased} was stemmed to \emph{diseas}). Once again, the same procedure was applied to the MFD words and the words in the Warriner et al. (2013) dataset. Using the Warriner et al. (2013) dictionary, the words in the MFD were assigned their valence value.

DESCRIBE MTMM NEW STUFF HERE? Basically, words found through that project were imported and added to each foundation, with redundancies removed at the end.

Words from the source article words were then compiled into a dataset where they were paired up with the MFD words (where applicable) as well as their percent occurrence and valence. At the end of this process, the percentage of the number of words from each moral foundation appearing in the articles was computed. This procedure created five percentages serving as the dependent variable for the multilevel model. Valence scores for the MFD words were \emph{z}-scored, allowing for the possibility of negative valence scores.

\hypertarget{experiment-2-results}{%
\section{Experiment 2 results}\label{experiment-2-results}}

\hypertarget{discussion-1}{%
\section{Discussion}\label{discussion-1}}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

How it turned out

Limitations of this one (no rationale behind choosing sources except \enquote{people say NPR's liberal??})

What to do for future project (focus on one MF? Different sources? More sources?)

Argue: why is still a good thing to study?? (probably something about current state of discourse, information, truth, \enquote{alternative facts,} subjective reality - philosophical stuff)

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-Aust2017}{}%
Aust, F., \& Barth, M. (2017). papaja: Create APA manuscripts with R Markdown. Retrieved from \url{https://github.com/crsh/papaja}

\leavevmode\hypertarget{ref-Bradley1999}{}%
Bradley, M. M., \& Lang, P. J. (1999). \emph{Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings} (No. C-1). The Center for Research in Psychophysiology, University of Florida.

\leavevmode\hypertarget{ref-Cameron2006}{}%
Cameron, D. (2006). Ideology and language. \emph{Journal of Political Ideologies}, \emph{11}(2), 141--152. doi:\href{https://doi.org/10.1080/13569310600687916}{10.1080/13569310600687916}

\leavevmode\hypertarget{ref-Clinton2014}{}%
Clinton, J. D., \& Enamorado, T. (2014). The National News Media's Effect on Congress: How Fox News Affected Elites in Congress. \emph{The Journal of Politics}, \emph{76}(4), 928--943. doi:\href{https://doi.org/10.1017/S0022381614000425}{10.1017/S0022381614000425}

\leavevmode\hypertarget{ref-Druckman2004}{}%
Druckman, J. N., Jacobs, L. R., \& Ostermeier, E. (2004). Candidate Strategies to Prime Issues and Image. \emph{The Journal of Politics}, \emph{66}(4), 1180--1202. doi:\href{https://doi.org/10.1111/j.0022-3816.2004.00295.x}{10.1111/j.0022-3816.2004.00295.x}

\leavevmode\hypertarget{ref-Feinerer2017}{}%
Feinerer, I., \& Hornik, K. (2017). Text mining package. Retrieved from \url{http://tm.r-forge.r-project.org/}

\leavevmode\hypertarget{ref-Gelman2006}{}%
Gelman, A. (2006). Multilevel (hierarchical) modeling: What it can and cannot do. \emph{Technometrics}, \emph{48}(3), 432--435. doi:\href{https://doi.org/10.1198/004017005000000661}{10.1198/004017005000000661}

\leavevmode\hypertarget{ref-Graham2009}{}%
Graham, J., Haidt, J., \& Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. \emph{Journal of Personality and Social Psychology}, \emph{96}(5), 1029--1046. doi:\href{https://doi.org/10.1037/a0015141}{10.1037/a0015141}

\leavevmode\hypertarget{ref-Graham2011}{}%
Graham, J., Nosek, B. A., Haidt, J., Iyer, R., Koleva, S., \& Ditto, P. H. (2011). Mapping the moral domain. \emph{Journal of Personality and Social Psychology}, \emph{101}(2), 366--385. doi:\href{https://doi.org/10.1037/a0021847}{10.1037/a0021847}

\leavevmode\hypertarget{ref-Haidt2007}{}%
Haidt, J., \& Graham, J. (2007). When Morality Opposes Justice: Conservatives Have Moral Intuitions that Liberals may not Recognize. \emph{Social Justice Research}, \emph{20}(1), 98--116. doi:\href{https://doi.org/10.1007/s11211-007-0034-z}{10.1007/s11211-007-0034-z}

\leavevmode\hypertarget{ref-Kuperman2014}{}%
Kuperman, V., Estes, Z., Brysbaert, M., \& Warriner, A. B. (2014). Emotion and language: Valence and arousal affect word recognition. \emph{Journal of Experimental Psychology: General}, \emph{143}(3), 1065--1081. doi:\href{https://doi.org/10.1037/a0035669}{10.1037/a0035669}

\leavevmode\hypertarget{ref-Kuperman2012}{}%
Kuperman, V., Stadthagen-Gonzalez, H., \& Brysbaert, M. (2012). Age-of-acquisition ratings for 30,000 English words. \emph{Behavior Research Methods}, \emph{44}(4), 978--990. doi:\href{https://doi.org/10.3758/s13428-012-0210-4}{10.3758/s13428-012-0210-4}

\leavevmode\hypertarget{ref-Mitchell2014}{}%
Mitchell, A., Matsa, K. E., Gottfried, J., \& Kiley, J. (2014). Political Polarization \& Media Habits \textbar{} Pew Research Center. Retrieved from \url{http://www.journalism.org/2014/10/21/political-polarization-media-habits/}

\leavevmode\hypertarget{ref-OConnell2018}{}%
O'Connell, M. (2018). Ford-Kavanaugh Ratings: Hearing Brings 20 Million Viewers to Cable and Broadcast \textbar{} Hollywood Reporter. Retrieved from \url{https://www.hollywoodreporter.com/live-feed/ford-kavanaugh-ratings-hearing-brings-20-million-viewers-cable-broadcast-1147785}

\leavevmode\hypertarget{ref-Pennebaker2007}{}%
Pennebaker, J. W., Booth, R. J., \& Frances, M. E. (2007). Liwc2007: Linguistic inquiry and word count. Austin, TX.

\leavevmode\hypertarget{ref-Pinheiro2017}{}%
Pinheiro, J., Bates, D., Debroy, S., Sarkar, D., \& Team, R. C. (2017). nlme: Linear and nonlinear mixed effects models. Retrieved from \url{https://cran.r-project.org/package=nlme}

\leavevmode\hypertarget{ref-Schmidt2017}{}%
Schmidt, M. F., Gonzalez-Cabrera, I., \& Tomasello, M. (2017). Children's developing metaethical judgments. \emph{Journal of Experimental Child Psychology}, \emph{164}, 163--177. doi:\href{https://doi.org/10.1016/j.jecp.2017.07.008}{10.1016/j.jecp.2017.07.008}

\leavevmode\hypertarget{ref-Warriner2015}{}%
Warriner, A. B., \& Kuperman, V. (2015). Affective biases in English are bi-dimensional. \emph{Cognition and Emotion}, \emph{29}(7), 1147--1167. doi:\href{https://doi.org/10.1080/02699931.2014.968098}{10.1080/02699931.2014.968098}

\leavevmode\hypertarget{ref-Warriner2013}{}%
Warriner, A. B., Kuperman, V., \& Brysbaert, M. (2013). Norms of Valence, Arousal, and Dominance for 13,915 English Lemmas. \emph{Behavior Research Methods}, \emph{45}(4), 1191--1207.

\endgroup


\end{document}
